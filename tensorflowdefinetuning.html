<!DOCTYPE html>
<html lang="japanese">
<head>
        <meta charset="utf-8" />
        <title>tensorflowでFineTuning</title>
        <link rel="stylesheet" href="https://sassea34.github.io/theme/css/main.css" />

        <!--[if IE]>
            <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
        <![endif]-->
</head>

<body id="index" class="home">
        <header id="banner" class="body">
                <h1><a href="https://sassea34.github.io/">sassea34's blog </a></h1>
                <nav><ul>
                    <li><a href="https://sassea34.github.io/category/algorithm.html">Algorithm</a></li>
                    <li class="active"><a href="https://sassea34.github.io/category/deep-learning.html">Deep Learning</a></li>
                    <li><a href="https://sassea34.github.io/category/dl-viewer.html">DL Viewer</a></li>
                    <li><a href="https://sassea34.github.io/category/game-make.html">Game Make</a></li>
                </ul>
                </nav>
        </header><!-- /#banner -->
<section id="content" class="body">
  <article>
    <header>
      <h1 class="entry-title">
        <a href="https://sassea34.github.io/tensorflowdefinetuning.html" rel="bookmark"
           title="Permalink to tensorflowでFineTuning">tensorflowでFineTuning</a></h1>
    </header>

    <div class="entry-content">
<footer class="post-info">
        <span>土 16 11月 2019</span>

</footer><!-- /.post-info -->      <h1>tensorflowでFineTuning</h1>
<h2>１．背景</h2>
<ul>
<li>tensorflowにまだまだ慣れていないが、FineTuningを行う必要が出てきました。<ul>
<li>本番で活用する前に、tensorflowでFineTuningを行う際の自己学習メモとして記録。</li>
<li>先人のやり方を最大限／時短で吸収したい。</li>
<li>実PJで使う際に必要になりそうな要素を勉強する。（どうやってデータを配置すべきか等）</li>
</ul>
</li>
</ul>
<hr>
<h2>２．FineTuningをとりあえず動かす。</h2>
<ol>
<li>画像セットの入手<ul>
<li>参考サイトより、本データベースの存在を知る。テストにちょうど良い規模感でしょうか。</li>
<li><a href="http://www.robots.ox.ac.uk/~vgg/data/flowers/17/">17 Category Flower Dataset</a>のダウンロード<ul>
<li><code>Downloads =&gt; Dataset images</code>より、<code>17flowers.tgz</code>を入手。</li>
</ul>
</li>
</ul>
</li>
<li>ソースコードの入手<ul>
<li>参考サイト１より、ソースコードを入手。</li>
</ul>
</li>
<li>Fine Tuning（学習）<ol>
<li>画像データ準備<ul>
<li><code>setup.py</code>により、画像データを<code>train_images</code>と<code>test_images</code>のフォルダに分けて保存。</li>
</ul>
</li>
<li>学習：<code>finetuning.py</code>を実施。<ul>
<li>Fine Tuningのエッセンスはここにあると予想。</li>
<li>plotのimportでエラーが出て動作しない。<ul>
<li>該当箇所
    <code>python
    from keras.utils.visualize_util import plot
    #from keras.utils.vis_utils import plot</code></li>
<li>keras.utils.visualize_utilが、leras.utils.vis_utilsに変更されたとの情報あり、変更するもplot見つからず。</li>
<li>コアな部分でないので、とりあえずコメントでつぶしてしまい、先に進む。<ul>
<li>飛ばすのは良くはありませんが・・本番で使いたいのはFront-end tensorflow, Back-end kerasで、本ソースコードとは逆だったりするので、後で落ち着いて対処すればいい。</li>
</ul>
</li>
</ul>
</li>
<li>GPUマシン（末記の検証環境）にて、50分ほどで学習完了。</li>
</ul>
</li>
</ol>
</li>
<li>予測／推論の実行<ul>
<li><code>predict.py</code>実行。Tulip画像がTulip　1位で推論された。
    <code>python
    (py3.6_tf1.5.0) &gt;python predict.py .\test_images\Tulip\image_0012.jpg
    ('Tulip', 0.9972982)
    ('Daffodil', 0.0010603186)
    ('Sunflower', 0.0004312605)
    ('Iris', 0.00036461666)
    ('Dandelion', 0.00031871776)</code></li>
<li>
<p><code>evaluate.py</code>実行。</p>
<p><code>python
(py3.6_tf1.5.0) &gt;python evaluate.py
loss, acc = model.evaluate_generator(test_generator, val_samples=nb_test_samples)
0.266931531164304 0.8876451073989742</code>
    * とりあえず、上手く動かせたか。</p>
</li>
</ul>
</li>
</ol>
<hr>
<h2>３．Fine Tuningに必要な要素（学習メモ）</h2>
<ol>
<li>
<p>Kerasのgenerator</p>
<ul>
<li>generatorに　train/testのデータ（フォルダ）や、augmentation有無などを指定して学習スタート、といった使い方。<ul>
<li>入力画像データは、train/testのフォルダ分けをしておくのが1つのやり方であることと理解。</li>
<li>フォルダ分けをしなくても、例えばファイルパスのリストを与えるなど、あるのかどうかを調査。<ul>
<li><a href="https://keras.io/preprocessing/image/">Keras Documentation ImageDataGenerator class</a><ul>
<li>今回のサンプルコードでは、<code>flow_from_directory</code>を利用している。</li>
<li><code>flow_from_dataframe</code>が使える。pandasのdataframeで、公式に記載のフォーマットで記載されていればよい。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Fine Tuningのやり方</p>
<ul>
<li>Networkの重みの固定の仕方で、セオリーでは以下と理解。<ol>
<li>特徴抽出：学習済み畳み込みベース（CNN部分）を凍結し、学習済み分類器（全結合層部分）を新しい分類器で学習。</li>
<li>ファインチューニング：新しく追加した分類器（全結合層部分）と、それに近い畳み込みブロック（VGG16で言えばブロック５）の重みを再学習。</li>
</ol>
</li>
<li>今回使ったサンプルコードでは、上記の1を飛ばして、直接2を実行している。<ul>
<li>その根拠としては、以下の　<code>block5_conv1 (Conv2D)</code> 以降の重みを再学習している。<ul>
<li>確認１：プログラム中でfreezeしている層を確認。
    <code>python
    # 最後のconv層の直前までの層をfreeze
    for layer in model.layers[:15]:
        layer.trainable = False</code></li>
<li>確認２：VGG16と全結合層を結合した学習用のモデルを出力。
    <code>python
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #
    =================================================================
    input_1 (InputLayer)         (None, 150, 150, 3)       0
    _________________________________________________________________
    block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792
    _________________________________________________________________
    block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928
    _________________________________________________________________
    block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0
    _________________________________________________________________
    block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856
    _________________________________________________________________
    block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584
    _________________________________________________________________
    block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0
    _________________________________________________________________
    block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168
    _________________________________________________________________
    block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080
    _________________________________________________________________
    block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080
    _________________________________________________________________
    block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0
    _________________________________________________________________
    block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160
    _________________________________________________________________
    block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808
    _________________________________________________________________
    block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808
    _________________________________________________________________
    block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0
    _________________________________________________________________
    block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808
    _________________________________________________________________
    block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808
    _________________________________________________________________
    block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808
    _________________________________________________________________
    block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0
    _________________________________________________________________
    sequential_1 (Sequential)    (None, 17)                2101777
    =================================================================
    Total params: 16,816,465
    Trainable params: 9,181,201
    Non-trainable params: 7,635,264
    _________________________________________________________________</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>
<p>ソースコード別理解</p>
<ul>
<li>他のソースコードの内容も確認し、Fine Tuningで勉強すべきトピックを確認する。</li>
<li>
<p>ソースコードと役割の確認</p>
<ul>
<li>データの準備<ul>
<li>setup.py</li>
</ul>
</li>
<li>学習メイン<ul>
<li>finetuning.py</li>
<li>vgg_scratch.py : VGG16の重みをランダム化した場合。学習が上手くいかない例のはず。</li>
<li>finetuning_with_preprocess.py : 前処理を使っている。<font color="pink">別途調査したい。</font></li>
</ul>
</li>
<li>
<p>推論</p>
<ul>
<li>predict.py  : 画像１枚のみの推論</li>
<li>evaluate.py : テストデータ全体の推論</li>
<li>predict_with_preprocess.py : 画像１枚のみの推論。前処理を使っている。</li>
</ul>
</li>
<li>
<p>可視化</p>
<ul>
<li>extractor.py : ボトルネック特徴量（FC層の直前の出力）をファイルに保存。<font color="pink">モデルの検証方法として使えるかを調査したい。</font></li>
<li>plot_results.py : matplotlibで学習ログを可視化</li>
</ul>
</li>
<li>
<p>helperと単純な？cnn</p>
<ul>
<li>smallcnn.py</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<hr>
<h2>４．参考サイト／書籍</h2>
<ol>
<li>PythonとKerasによるディープラーニング（マイナビ出版）<ul>
<li>Fine Tuningの考え方が載っていて、参考になった。</li>
</ul>
</li>
<li><a href="http://aidiary.hatenablog.com/entry/20170131/1485864665">VGG16のFine-tuningによる17種類の花の分類</a><ul>
<li>こちらからソースコードを入手して試行させて頂いた。</li>
</ul>
</li>
</ol>
<hr>
<h2>５．検証環境</h2>
<table>
<thead>
<tr>
<th>No</th>
<th>名称</th>
<th>状況</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>CPU</td>
<td>AMD Phenom(tm) II X6 1090T 3.20GHz<BR>これが<code>AVX（Advanced Vector Extensions）</code>を搭載しておらず、<BR>Tensorflowはver=1.5.0止まりとなってしまう。</td>
</tr>
<tr>
<td>2</td>
<td>GPU</td>
<td>GeForce GTX 1060 6GB<br>Jupyter notebookに多少メモリ開放バグあるみたい？<br>たまに6GB上限を気にするレベルで、とりあえずまだ大丈夫。</td>
</tr>
<tr>
<td>3</td>
<td>Memory</td>
<td>16GB<br>機械学習のため秋葉原で中古メモリ増設。4-&gt;16で色々快適に。</td>
</tr>
<tr>
<td>4</td>
<td>Python</td>
<td>Windows, Anaconda3-5.3.1 でver3.6の仮想環境（Tensorflow対応から3.6とした）</td>
</tr>
<tr>
<td>5</td>
<td>Tensorflow</td>
<td>Version 1.5.0<BR>Visual Studio 2015 Version 14.0.25431.01 Update 3<BR>CUDA V9.0.176<BR>cuDNN v7.0.5[Dec 5, 2017], for CUDA 9.0</td>
</tr>
</tbody>
</table>
    </div><!-- /.entry-content -->

  </article>
</section>
        <section id="extras" class="body">
                <div class="social">
                        <h2>social</h2>
                        <ul>

                            <li><a href="https://github.com/sassea34">GitHub</a></li>
                            <li><a href="http://www.z-z.jp/?sassea34">Message board</a></li>
                        </ul>
                </div><!-- /.social -->
        </section><!-- /#extras -->

        <footer id="contentinfo" class="body">
                <p>Powered by <a href="http://getpelican.com/">Pelican</a>. Theme <a href="https://github.com/blueicefield/pelican-blueidea/">blueidea</a>, inspired by the default theme.</p>
        </footer><!-- /#contentinfo -->

</body>
</html>